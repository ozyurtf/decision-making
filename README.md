**Note**: I took the core codebase for environment simulation and related infrastructure in this repository from my assignments in the Deep Decision Making and Reinforcement Learning (DDRL) course at New York University. I only implemented the Behavior Cloning, Goal-Conditioned Behavior Cloning, DAgger, Double Q-Learning, Dueling DQN, and PPO algorithms. Their performance are shown in the GIFs below.

## Behavior Cloning 

![Behavior Cloning](figures/behavior-cloning.png)

<table>
    <tr>
        <th>Changing</th>
        <th>Fixed</th>
        <th>Multimodal</th>
    </tr>
    <tr>
        <td align="center"><img src="./gifs/behavior-cloning/changing/changing.gif" alt="Changing" width="245"/></td>
        <td align="center"><img src="./gifs/behavior-cloning/fixed/fixed.gif" alt="Fixed" width="245"/></td>
        <td align="center"><img src="./gifs/behavior-cloning/multimodal/multimodal.gif" alt="Multimodal" width="245"/></td>
    </tr>
</table>

## Goal Conditioned Behavior Cloning

![Goal-Conditioned Behavior Cloning](figures/goal-conditioned-behavior-cloning.png)


<table>
    <tr>
        <th>Changing</th>
        <th>Fixed</th>
    </tr>
    <tr>
        <td align="center"><img src="./gifs/goal-conditioned-behavior-cloning/changing/changing.gif" alt="Changing" width="375"/></td>
        <td align="center"><img src="./gifs/goal-conditioned-behavior-cloning/fixed/fixed.gif" alt="Fixed" width="375"/></td>
    </tr>
</table>

## Behavior Transformer 

## Dagger

## Double Q-Learning 

## Dueling DQN 

## Reinforce 

## PPO 



